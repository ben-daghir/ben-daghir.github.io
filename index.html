<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Machine Learning for Satellite Crop Classification</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="css/normalize.css" media="screen">
    <link rel="stylesheet" type="text/css" href="css/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="css/github-light.css" media="screen">
    <link rel="stylesheet" href="css/style.css">
    <script src="js/jquery.min.js"></script>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <script src="js/jquery.csv.min.js"></script>
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Machine Learning for Satellite Crop Classification</h1>
      <h2 class="project-tagline"></h2>
      <a href="https://github.gatech.edu/kvu35/CS4641-Project" class="btn">View on GitHub</a>
    </section>

    <section class="main-content">
      <h2>The Problem and Motivation
        <a id="Introduction" class="anchor" href="#welcome-to-github-pages" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span>
        </a>
      </h2>
      <p>
        Agriculture is very important to the global community, not only to provide a basic need for human survival but
        also as a main driver of economic growth, especially in developing countries. Having accurate and reliable
        agricultural data is essential for food security and to monitor economic growth. Having data taken from
        satellites of different regions over time can be helpful in building models to monitor agriculture to help
        increase farming productivty and prevent possible losses. Compared to surveying land using traditional methods,
        being able to use satellite data provides more accuracy and provides data at a scale with high spatial granularity.
        However, the large amount of data taken needs to be able to be analyzed efficiently to help predict useful
        information. For this project we chose to focus on the problem of identifying crop types from satellite images
        as there are many different types of crops being grown in a region and it is essential to first identify the
        crop type before analyzing any trends.
      </p>
    </section>

    <section>
      <div class="main-content">

        <h2>
          Data
          <a id="Data" class="anchor" href="#designer-templates" aria-hidden="true">
          <span aria-hidden="true" class="octicon octicon-link"></span></a>
        </h2>
        <p>
          The dataset we used for our project comes from the Radiant Earth MLHub and was accessed via a RESTful API.
          The dataset contains over four thousand time-series raster images of farmland fields taken by a Sentinel-2
          satellite. The images taken consist of 12 separate frequency spectrum imaging bands and cloud interference
          probability for each pixel. Images are taken every month within the growing cycle and multiple fields can be
          present in one image which results in some fields only being a few pixels wide. We used 3286 images for training
          our models and 1402 images were provided for testing. Our project will attempt to correctly classify the results
          into the 7 â€˜crop idsâ€™ provided by the dataset with the highest accuracy possible.
        </p>
      </div>

      <div id="image-visualizer" class="container">
        <div id="image-k" class="image">
            <img src="images/k.png" class="image image-k"/>
            <span style="opacity: 0" class="image-caption">Bands 01, 05 - 09, CLD <br>Invisible Spectrum, Cloud Data</span>
            <span style="opacity: 0; top:-65px;" class="diagram-caption">All Image Spectral Bands<br>(Features)</span>
        </div>
        <div id="image-b" class="image">
            <img src="images/b.png" class="image image-b"/>
            <span style="opacity: 0" class="image-caption">Band 02<br>Visible Blue</span>
        </div>
        <div id="image-g" class="image">
            <img src="images/g.png" class="image image-g"/>
            <span style="opacity: 0" class="image-caption">Band 03<br>Visible Green</span>
        </div>
        <div id="image-r" class="image">
            <img src="images/r.png" class="image image-r"/>
            <span style="opacity: 0" class="image-caption">Band 04<br>Visible Red</span>
        </div>
        <div id="image-fids" class="image image-fids" style="opacity:0">
            <img src="images/fids.png" class="image"/>
            <span style="opacity: 0" class="diagram-caption">Field IDs<br>(Pre-Processing Data)</span>
        </div>
        <div id="image-labels" class="image image-labels" style="opacity:0">
            <img src="images/labels.png" class="image"/>
            <span style="opacity: 0" class="diagram-caption">Crop IDs<br>(Labels)</span>
        </div>
        <div id="floating-label" class="image floating-label">
          Scroll Over Me!
        </div>
        <div id="scroll-container" class="container">
            <div id="scroll-anchor" class="anchor"></div>
        </div>
      </div>
      <div class="main-content">
        <p>
          The tool below, known as a Parallel Coordinate plot or "ParaCoord" plot, is extremely useful diplaying relationships between
          the each field's features (each spectral band reading) and respective label (Crop ID). This is a quick tutorial
          on how to effectively use the tool.<br><br>
          Each continuous color-coded line spanning left-to-right corresponds to a single data point. There are multiple y-axes,
          13 to be exact, labeled at the top as either a spectral band (feature) or the data point's Crop ID (label).
          The data points with the same Crop ID (label) are the same color. The location on the y-axis where a data
          point's line crosses corresponds to its value for that given feature. This is where the tool becomes extremely
          powerful.<br><br>
          The tool allows us to create bypass filters to look at specific ranges for each feature or label. Every data
          point satisfying the filter range will be highlighted and the rest will be muted. For example, to look at
          data points with only Crop ID 4, click and drag directly on the Crop ID y-axis so that a filter is created
          over the value 4.<br><br>
          As you will see, only the lines corresponding to Crop ID 4 will be shown. This filter can be moved by
          dragging it up or down. You can very easily chain filters by clicking and dragging on different feature axes,
          creating a set of feature ranges. You can also add more than one filter per axis!<br><br>
          To remove all filters on an axis, just click the axis once, without dragging. That's it! See if you can create
          a filter set that shows only a single Crop ID. This is exactly what our Machine Learning models are trying to do in
          different ways!
        </p>
      </div>
      <div style="text-align:center;">
        <button onclick="applyFilters(1)">Apply Example Filter</button>
        <button onclick="applyFilters(0)">Remove Example Filter</button>
      </div>
       <div style="max-width: 1200px; margin: auto;" id="feature-analysis-plot"></div>
    </section>

    <section>
    <div class="main-content">
      <h3>Training and Testing Dataset:
        <a id="Training-testing-dataset" class="anchor" href="#creating-pages-manually" aria-hidden="true">
          <span aria-hidden="true" class="octicon octicon-link"></span>
        </a></h3>
        <p>
          For our training and testing dataset, we used the images provided with a known Field ID. We randomly chose
          80% of stratified image samples to train our model, leaving 20% left to train the model. This comes out to
          roughly 3500 data points to train and 875 data points to test. All of the images
          and label arrays are sized to be 2016 × 3035 pixels. The amount of data points within each image
          varies depending on satellite image. View <a href="#image-visualizer">here</a> to see how each image is broken
          down into its features and components.<br><br>
          For our Machine Learning Models, the feature data (X) is most easily broken down into a 3-dimnesional array.
          Because the data is a time-series, there are repetitive data points corresponding to the same field location
          in the image. The size of the input array (X) is naturally (N x B x D):<br><br>
          N = Number of Data Points<br>
          B = Number of Spectral Bands<br>
          D = Number of Dates in the Time Series<br><br>
          As most array cannot naturally ingest multiple dimensions,
        </p>
    </div>
    </section>
     <section>
      <div class="main-content">

      <h2>
        Strategy
        <a id="Strategy" class="anchor" href="#creating-pages-manually" aria-hidden="true">
          <span aria-hidden="true" class="octicon octicon-link"></span>
        </a>
      </h2>
      <p>
        We decided to approach this problem using two different methods:
    <ol>
        <li>Artificial Neural Networks (ANN) Multi-Layered Perceptron (MLP) Model</li>
        <li>Multi-Class Support Vector Machines (MSVM) Model</li>
    </ol>
      </p>
    </div>
    </section>


    <section>
      <div class="main-content">
        <h3>
          Artificial Neural Network (ANN): Multi-Layered Perceptron Model
          <a id="ANN" class="anchor" href="#creating-pages-manually" aria-hidden="true">
            <span aria-hidden="true" class="octicon octicon-link"></span>
          </a>
        </h3>
        <p>
        A Multi-Layered Perceptron (MLP) is a supervised learning algorithm that consists of an input, several hidden
          layers, and an output later. Each hidden layer has nodes that use activation functions. MLP then uses
          backpropogation to train the network and update the nodes. We chose to use this approach because the MLP
          can capture more complex and non-linear features in the dataset. Our MLP Model will use the twelve spectrum
          imaging bands and cloud data per field id in a single aggregated matrix form. Each matrix entry represents a
          pixel corresponding to a geographical field location. The output will be a column vector containing the
          probability that crop X was in that field id.
        </p>
        <p>
          We performed two different studies using the MLP model. The first was an activation study which tested how
          the loss and accuracy changed from using different activation functions for different epoch values. We also
          performed a hidden layer study in which we varied the number of hidden layers used. For both of these studies
          we utilized the functions built in to the Keras API.
        </p>

        <h4>Activation Function Study:</h4>
        <p> For this study we varied activation functions for different epoch values. One epoch is when the entire
          dataset is passed forward and backward through the neural network. As the number of epochs are increased
          the weights are changed in the neural network nore and the model will change from underfitting the data
          to becoming optimal and then overfitting which is why experimentation is needed for different datasets to
          determine the optimal epoch value. An activation function needs to be applied for a MLP model to allow the
          network to represent non-linear complex functional mappings between inputs and outputs. The optimal activaton
          function varies between datasets which is why we also varied the activation functions used for this study.
          We recorded losses and accuracy to determine the optimal epoch value and activation function for our dataset.
        </p>

        <div style="max-width: 1200px; margin: auto;" id="activation-function-study-softplus"></div>
        <div style="max-width: 1200px; margin: auto;" id="activation-function-study-uniform"></div>

        <h4>Hidden Layer Study:</h4>
        <p>For our hidden layer study we also varied the number of epochs for the reason explained in the previous
          section. For this study we also varied the number of hidden layers. A single-layer artificial neural
          network has a single layer of nodes and each node connects directly to an input variable and then contributes
          to an output variable. To create a multilayer perceptron a single layer netwrok is extended where it has an
          input layer that connects to the input variables, one or more hidden layers, and an output layer that produces
          the output variables. Because of the complexity of our dataset, a multi-layered model can be more accurate.
          To determine the optimal number of layers for our model, we need to experiment with different numbers of them
          which is what we do in this study.
        </p>

        <div style="max-width: 1200px; margin: auto;" id="hidden-layer-study"></div>

        <h4>ANN Model Results:</h4>
        <div style="max-width: 1200px; margin: auto;" id="Batch_size"></div>
        <div style="max-width: 1200px; margin: auto;" id="PCA_dims"></div>
        <div style="max-width: 1200px; margin: auto;" id="epochs"></div>
        <p>When comparing our activation studies and our hidden layer studies
          .....................
        </p>
      </div>
    </section>


     <section>
      <div class="main-content">
      <h3>
        Multi-Class Support Vector Machines (MSVM) Model

        <a id="MSVM" class="anchor" href="#creating-pages-manually" aria-hidden="true">
          <span aria-hidden="true" class="octicon octicon-link"></span>
        </a>
      </h3>
      <p>
        We chose to test a multi-class support vector machine model because SVMs are often used for classification
        tasks and tend to perform well with many problem types. An SVM constructs hyperplanes in multidimensional
        space that separates cases of different class labels. If your dataset has more than two classes (non-binary
        classification) then you use a multi-class suppor vector machine model. An SVM classifies data by determining
        the optimal hyperplane that separates observations according to their class labels. The main idea when using a
        MSVM is to transform the data to a higher dimension so hopefully the data will be linearly separable. Data
        points of one class can be mapped using mathematical functions called kernels and the mapped data points allow
        the MSVM model to find the optimal line to separate the classes. Different kernel types can be used and gamma
        and cost arguments can be varied where gamma represents the argument of the kernel function and cost specifies
        the cost of a violation to the margin. Experimenting with these values helps to find the best classification
        accuracy.
      </p>
      <h4>Methodology</h4>
      <p>
        In our case, we used Scikit learning’s implementation of the MSVC, which provides 3 options for built in Kernels (Linear, Polynomial and Radial Basis Function). We went with Radial Basis Functions, which has two parameters, gamma and C, that influence the shape of the decision boundary. Gamma describes how ‘curvy’ our decision boundary will be. The lower the boundary, the closer it is to a straight line. The higher, the more the distance to a labelled point determines the decision boundary. C describes the softness of decision boundary. Closer to zero indicates a decision boundary more tolerant of error, and the greater C the less tolerant or error the boundary becomes. From here, we create a small selection of possible gamma and C values and used a grid search algorithm to find the best possible hyperparameters.
      </p>
      <p>
        Using this methodology, we began to test training our model with the entirety of our dataset. Our goal at the outset was to reach an accuracy of 80%. Our immediate realization is that the time cost was so large, that we wanted to test to see how taking smaller samples of the data would impact our result. We decided to take records of accuracy and time spent on these smaller samples and record their performance.
      </p>
      <p>
        For our experiment, we took 30 samples of random partitions of the data such that each data point had a Possibility ‘P’ of being included in the training. So if P = 0.1, on average ten percent of training data was fit before testing.
        In addition, we came to this with some background understanding that plant chlorophyll drops significantly outside of a sweet spot within the visible light spectrum. Thus, we believed that the removal of data representing electromagnetic wavelengths outside the spectrum would not impact accuracy.
      </p>
      <h4>MSVM Study Results</h4>
       <div style="max-width: 1200px; margin: auto;" id="RGB-Band-Studies"></div>
      <div style="max-width: 1200px; margin: auto;" id="RGB-Band-Studies-Time"></div>
      <p>
        As you can see in the following graphs, the accuracy increases consistently as the amount of training data used approaches 100%. Accuracy at 0.9 exceeds 80%, our threshold for satisfaction. We can also see that this threshold is reached by smaller subsets of the data. Most interestingly, we see that we can arrive at the 80% accuracy using only the bands of electromagnetic spectrum within the visible light spectrum, and 80% of our training data. The time taken to get to this result was approximately 35% of the cost of our most expensive observation, 90% of training data across all bands.
      </p>
      <p>
        The loss of accuracy when dropping all electromagnetic bands outside of the visible spectrum never exceeded 5 percent, but more than halved the time taken to train the SVM model (except in the smallest proportion of data 10%) This has important applications, because it reveals a way we can optimize our collection of data in the future. For example, if our analysis is time sensitive, we can reduce our training time ~50% by reducing features to RGB, and still expect results of at least 80% accuracy.
      </p>
    </div>
    </section>

      <section>
      <div class="main-content">
      <h2>
        Results
        <a id="Results" class="anchor" href="#creating-pages-manually" aria-hidden="true">
          <span aria-hidden="true" class="octicon octicon-link"></span>
        </a>
      </h2>
       <div style="max-width: 1200px; margin: auto;" id="All-Studies-Accuracy"></div>
      <p>
        When comparing the MSVM Model to the Neural Networks from earlier, we see that accuracy is comparable between the two methods, with a slight edge for the Neural Network in the end. The Neural Network predictions were 93% for the final model, compared to 90% in the all data case for MCSVM. This shows that Neural Networks perform slightly better than our implementation for multi-classification support vector machines.

      </p>

      </div>
    </section>

     <section>
      <div class="main-content">
      <h2>
        Discussion
        <a id="Discussion" class="anchor" href="#creating-pages-manually" aria-hidden="true">
          <span aria-hidden="true" class="octicon octicon-link"></span>
        </a>
      </h2>
      <p>
        Discussion
      </p>
    </div>
    </section>

     <section>
      <div class="main-content">
      <h2>
        Authors and Contributors
        <a id="authors-and-contributors" class="anchor" href="#authors-and-contributors" aria-hidden="true">
          <span aria-hidden="true" class="octicon octicon-link"></span>
        </a>
      </h2>
      <p>
        Luka Derado, Benjamin Daghir, Erin McCaskey, Khang Vu (@),(@), (@)
      </p>
    </div>
    </section>

     <section>
      <div class="main-content">
      <h3>
        Support or Contact
        <a id="support-or-contact" class="anchor" href="#support-or-contact" aria-hidden="true">
          <span aria-hidden="true" class="octicon octicon-link"></span>
        </a>
      </h3>
      <p>
        Having trouble with Pages? Check out our <a href="https://help.github.com/pages">documentation</a>
        or <a href="https://github.com/contact">contact support</a> and weâ€™ll help you sort it out.
      </p>
    </div>
    </section>

    <section class="main-content">
      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.gatech.edu/kvu35/CS4641-Project">
          Cs4641-project</a> is maintained by <a href="https://github.gatech.edu/kvu35">kvu35</a>.</span>
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">
          GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a>
          by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>
    </section>
  </body>

  <script src="js/main.js"></script>
  <script src="js/plotly.js"></script>
</html>
